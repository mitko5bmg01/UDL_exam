{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wSX2qaMrp4oP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bSCKLNktp5TN"
      },
      "outputs": [],
      "source": [
        "# compute KL(X || Y)\n",
        "# where X and Y are d-dim. vectors with indep. coordinates s.t.\n",
        "# X_i ~ N(mu_x_i, exp(log_sigma_x_i)) and\n",
        "# Y_i ~ N(mu_y_i, exp(log_sigma_y_i))\n",
        "def KL_divergence(mu_x, log_sigma_x, mu_y, log_sigma_y):\n",
        "    kl = log_sigma_y - log_sigma_x + 0.5 * (torch.exp(2 * log_sigma_x) + \\\n",
        "           (mu_x - mu_y)**2) / torch.exp(2 * log_sigma_y) - 0.5\n",
        "\n",
        "    axes_to_reduce = list(range(1, len(list(mu_x.shape))))\n",
        "    return torch.sum(kl, axes_to_reduce)\n",
        "\n",
        "\"\"\"\n",
        "# compute KL(X || Y)\n",
        "# where X and Y are d-dim. vectors with indep. coordinates s.t.\n",
        "# X_i ~ Lap(mu_x_i, exp(log_b_x_i)) and\n",
        "# Y_i ~ Lap(mu_y_i, exp(log_b_y_i))\n",
        "def KL_divergence(mu_x, log_b_x, mu_y, log_b_y):\n",
        "    kl = (torch.exp(log_b_x - torch.abs(mu_x - mu_y) / torch.exp(log_b_x)) + \\\n",
        "         torch.abs(mu_x - mu_y)) / torch.exp(log_b_y) + log_b_y - log_b_x - 1.0\n",
        "\n",
        "    axes_to_reduce = list(range(1, len(list(mu_x.shape))))\n",
        "    return torch.sum(kl, axes_to_reduce)\"\"\"\n",
        "\n",
        "# sample from N ~ N(mu, log_sigma)\n",
        "def sample_gaussian(mu, log_sigma):\n",
        "    return mu + torch.exp(log_sigma) * torch.randn(mu.shape).to(mu.device)\n",
        "\n",
        "# sample from L ~ Lap(mu, log_b)\n",
        "def sample_laplace(mu, log_b):\n",
        "    shape = mu.get_shape()\n",
        "    x = torch.log(torch.rand(shape, dtype=tf.float32)) - \\\n",
        "        torch.log(torch.rand(shape, dtype=tf.float32))\n",
        "    return mu + tf.exp(log_b) * x\n",
        "\n",
        "def bernoulli_log_likelihood(x, mu):\n",
        "    log_likelihood = x * torch.log(torch.clamp(mu, 1e-9, 1.0)) \\\n",
        "                      + (1.0 - x) * torch.log(torch.clamp(1.0 - mu, 1e-9, 1.0))\n",
        "\n",
        "    axes_to_reduce = list(range(1, len(list(x.shape))))\n",
        "    return torch.sum(log_likelihood, axes_to_reduce)\n",
        "\n",
        "def normal_log_likelihood(x, mu, log_sigma):\n",
        "    log_likelihood = -0.5 * np.log(2 * np.pi) - log_sigma \\\n",
        "                      - 0.5 * ((x - mu) / torch.exp(log_sigma)) ** 2\n",
        "\n",
        "    axes_to_reduce = list(range(1, len(list(x.shape))))\n",
        "    return torch.sum(log_likelihood, axes_to_reduce)\n",
        "\n",
        "def laplace_log_likelihood(x, mu, log_sigma):\n",
        "    log_likelihood = -log_sigma - torch.abs(x - mu) / torch.exp(log_sigma) - np.log(2.0)\n",
        "\n",
        "    axes_to_reduce = list(range(1, len(list(x.shape))))\n",
        "    return torch.sum(log_likelihood, axes_to_reduce)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-Iozxftvp7VT"
      },
      "outputs": [],
      "source": [
        "class RandomisedLinearModule(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, activation):\n",
        "        super().__init__()\n",
        "\n",
        "        scale = np.sqrt(6.0/(in_dim + out_dim))\n",
        "\n",
        "        self.mu_W = nn.Parameter(torch.rand(out_dim, in_dim) * 2 * scale - scale)\n",
        "        self.log_sigma_W = nn.Parameter(torch.ones(out_dim, in_dim, dtype=torch.float32) * (-6.0))\n",
        "        self.mu_b = nn.Parameter(torch.zeros(out_dim, dtype=torch.float32))\n",
        "        self.log_sigma_b = nn.Parameter(torch.ones(out_dim, dtype=torch.float32) * (-6.0))\n",
        "\n",
        "        self.mu_W_prior = torch.zeros(out_dim, in_dim, dtype=torch.float32, device=\"cuda:0\")\n",
        "        self.log_sigma_W_prior = torch.zeros(out_dim, in_dim, dtype=torch.float32, device=\"cuda:0\")\n",
        "        self.mu_b_prior = torch.zeros(out_dim, dtype=torch.float32, device=\"cuda:0\")\n",
        "        self.log_sigma_b_prior = torch.zeros(out_dim, dtype=torch.float32, device=\"cuda:0\")\n",
        "\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, x, sampling_mode=True):\n",
        "        if sampling_mode:\n",
        "            #W = sample_laplace(self.mu_W, self.log_sigma_W)\n",
        "            #b = sample_laplace(self.mu_b, self.log_sigma_b)\n",
        "            W = sample_gaussian(self.mu_W, self.log_sigma_W)\n",
        "            b = sample_gaussian(self.mu_b, self.log_sigma_b)\n",
        "        else:\n",
        "            W = self.mu_W\n",
        "            b = self.mu_b\n",
        "\n",
        "        return self.activation(F.linear(x, W, b))\n",
        "\n",
        "    def KL_div(self):\n",
        "        return KL_divergence(self.mu_W, self.log_sigma_W, self.mu_W_prior, self.log_sigma_W_prior).sum() + \\\n",
        "               KL_divergence(self.mu_b, self.log_sigma_b, self.mu_b_prior, self.log_sigma_b_prior).sum()\n",
        "\n",
        "    def update_prior(self):\n",
        "        with torch.no_grad():\n",
        "            self.mu_W_prior.copy_(self.mu_W)\n",
        "            self.log_sigma_W_prior.copy_(self.log_sigma_W)\n",
        "            self.mu_b_prior.copy_(self.mu_b)\n",
        "            self.log_sigma_b_prior.copy_(self.log_sigma_b)\n",
        "\n",
        "    def reset_log_sigmas(self):\n",
        "        with torch.no_grad():\n",
        "            self.log_sigma_W.copy_(torch.full_like(self.log_sigma_W, -6.0))\n",
        "            self.log_sigma_b.copy_(torch.full_like(self.log_sigma_b, -6.0))\n",
        "\n",
        "class SharedModule(nn.Module):\n",
        "    def __init__(self, dim_x, dim_h, n_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.layers_list = nn.ModuleList(\n",
        "            [RandomisedLinearModule(dim_h, dim_h, F.relu) for _ in range(n_layers-1)] + \\\n",
        "            [RandomisedLinearModule(dim_h, dim_x, F.sigmoid)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x, sampling_mode=True):\n",
        "        for layer in self.layers_list:\n",
        "            x = layer(x, sampling_mode)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def KL_div(self):\n",
        "        kl_div = 0.0\n",
        "        for layer in self.layers_list:\n",
        "            kl_div += layer.KL_div()\n",
        "\n",
        "        return kl_div\n",
        "\n",
        "    def update_prior(self):\n",
        "        for layer in self.layers_list:\n",
        "            layer.update_prior()\n",
        "\n",
        "    def reset_log_sigmas(self):\n",
        "        for layer in self.layers_list:\n",
        "            layer.reset_log_sigmas()\n",
        "\n",
        "\n",
        "class TaskSpecificModule(nn.Module):\n",
        "    def __init__(self, dim_z, dim_h, n_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers_list = nn.ModuleList(\n",
        "            [RandomisedLinearModule(dim_z, dim_h, F.relu)] + \\\n",
        "            [RandomisedLinearModule(dim_h, dim_h, F.relu) for _ in range(n_layers-1)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x, sampling_mode=True):\n",
        "        for layer in self.layers_list:\n",
        "            x = layer(x, sampling_mode)\n",
        "        return x\n",
        "\n",
        "class GeneratorModule(nn.Module):\n",
        "    def __init__(self, dim_z, dim_x, dim_h, n_tasks, n_layers_shared, n_layers_taskspec):\n",
        "        super().__init__()\n",
        "\n",
        "        self.shared_module = SharedModule(dim_x, dim_h, n_layers_shared)\n",
        "\n",
        "        self.taskspec_modules = nn.ModuleList(\n",
        "            [TaskSpecificModule(dim_z, dim_h, n_layers_taskspec) for _ in range(n_tasks)]\n",
        "        )\n",
        "\n",
        "    def forward(self, z, task_ind, sampling_mode=True):\n",
        "        x = self.taskspec_modules[task_ind](z, sampling_mode)\n",
        "        x = self.shared_module(x, sampling_mode)\n",
        "        return x\n",
        "\n",
        "    def KL_div_shared_prior_post(self):\n",
        "        return self.shared_module.KL_div()\n",
        "\n",
        "    def update_shared_params_prior(self):\n",
        "        self.shared_module.update_prior()\n",
        "\n",
        "    def reset_shared_params_log_sigmas(self):\n",
        "        self.shared_module.reset_log_sigmas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nPS-GtuIs-iS"
      },
      "outputs": [],
      "source": [
        "class LinearModule(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        scale = np.sqrt(6.0/(in_dim + out_dim))\n",
        "\n",
        "        self.W = nn.Parameter(torch.rand(out_dim, in_dim, dtype=torch.float32) * 2 * scale - scale)\n",
        "        self.b = nn.Parameter(torch.zeros(out_dim, dtype=torch.float32))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.linear(x, self.W, self.b)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, dim_z, dim_x, dim_h, n_layers_shared, n_layers_taskspec):\n",
        "        super().__init__()\n",
        "        self.n_inner_layers = n_layers_shared + n_layers_taskspec\n",
        "\n",
        "        self.mlp_module = nn.ModuleList(\n",
        "            [LinearModule(dim_x, dim_h)] + \\\n",
        "            [LinearModule(dim_h, dim_h) for _ in range(self.n_inner_layers - 2)] + \\\n",
        "            [LinearModule(dim_h, 2*dim_z)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, layer in enumerate(self.mlp_module):\n",
        "            x = layer(x)\n",
        "            if i < self.n_inner_layers - 1:\n",
        "                x = F.relu(x)\n",
        "\n",
        "        mu, log_sigma = x[:, :x.shape[1] // 2], x[:, (x.shape[1] // 2):]\n",
        "\n",
        "        return mu, log_sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bSXKsMettAmi"
      },
      "outputs": [],
      "source": [
        "hyperparams = {\n",
        "    'dim_z' : 50,\n",
        "    'dim_h' : 500,\n",
        "    'dim_x' : 28 ** 2,\n",
        "    'n_layers_shared': 2,\n",
        "    'n_layers_taskspec': 2,\n",
        "    'n_tasks': 10,\n",
        "    'batch_size': 50,\n",
        "    'n_epochs': 200,\n",
        "    'lr': 1e-4,\n",
        "    'sampling_mode': False\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DJur6_n2tFnr"
      },
      "outputs": [],
      "source": [
        "# alter these when changing the dataset\n",
        "\n",
        "task_labels = list(range(hyperparams['n_tasks']))\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7k4GUPrttI3Y"
      },
      "outputs": [],
      "source": [
        "task_traindata_dict = {label: None for label in task_labels}\n",
        "task_testdata_dict = {label: None for label in task_labels}\n",
        "\n",
        "for label in task_labels:\n",
        "    train_mask = [i for i in range(len(trainset)) if trainset.targets[i] == label]\n",
        "    test_mask = [i for i in range(len(testset)) if testset.targets[i] == label]\n",
        "\n",
        "    task_traindata_dict[label] = DataLoader(\n",
        "        torch.utils.data.Subset(trainset, train_mask),\n",
        "        batch_size=hyperparams['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    task_testdata_dict[label] = DataLoader(\n",
        "        torch.utils.data.Subset(testset, test_mask),\n",
        "        batch_size=hyperparams['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "generator = GeneratorModule(\n",
        "    hyperparams['dim_z'],\n",
        "    hyperparams['dim_x'],\n",
        "    hyperparams['dim_h'],\n",
        "    hyperparams['n_tasks'],\n",
        "    hyperparams['n_layers_shared'],\n",
        "    hyperparams['n_layers_taskspec']\n",
        ").to(device)\n",
        "\n",
        "encoder = Encoder(\n",
        "    hyperparams['dim_z'],\n",
        "    hyperparams['dim_x'],\n",
        "    hyperparams['dim_h'],\n",
        "    hyperparams['n_layers_shared'],\n",
        "    hyperparams['n_layers_taskspec']\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CpP8NpB3tiPg"
      },
      "outputs": [],
      "source": [
        "def compute_loss(x_train, enc, gen, task, total_data, K=10):\n",
        "    # K - number of samples used for Monte Carlo approximation of the expectation\n",
        "    z_post_mu, z_post_log_sigma = enc(x_train)\n",
        "\n",
        "    # compute KL(q_phi(z|x) || p(z))   knowing z has indep N(0,1) coordinates\n",
        "    kl_z_prior_post = KL_divergence(z_post_mu, z_post_log_sigma,\n",
        "                                       torch.zeros(z_post_mu.shape).to(device), torch.zeros(z_post_mu.shape).to(device))\n",
        "\n",
        "    # compute KL divergence between prior and posterior of shared params\n",
        "    # KL(q_t(theta) || q_(t-1)(theta))\n",
        "    kl_shared_param = gen.KL_div_shared_prior_post()\n",
        "\n",
        "    # estimate E_q_phi_z [log(p_theta(x|z))]\n",
        "    # we model x ~ Ber(gen(z))\n",
        "    post_x_log_likelihood = 0.0\n",
        "    axes_to_reduce = list(range(1, len(list(x_train.shape))))\n",
        "\n",
        "    for _ in range(K):\n",
        "        #z = sample_laplace(z_post_mu, z_post_log_sigma)\n",
        "        z = sample_gaussian(z_post_mu, z_post_log_sigma)\n",
        "        x_mu = gen(z, task)\n",
        "        post_x_log_likelihood += bernoulli_log_likelihood(x_train, x_mu) / K\n",
        "\n",
        "    loss = kl_z_prior_post.mean() - post_x_log_likelihood.mean() + kl_shared_param / total_data\n",
        "\n",
        "    return loss, kl_z_prior_post.mean().item(), post_x_log_likelihood.mean().item(), kl_shared_param.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2q1TvlPDuhRI"
      },
      "outputs": [],
      "source": [
        "def eval_test_ll_on_task(task_testdata_dict, task, enc, gen, sampling_mode=True, K=100):\n",
        "    enc.eval(); gen.eval()\n",
        "\n",
        "    total_batches = len(task_testdata_dict[task])\n",
        "\n",
        "    test_ll_mean = 0.0\n",
        "    test_ll_std = 0.0\n",
        "\n",
        "    for data_batch, _ in task_testdata_dict[task]:\n",
        "        data_batch = data_batch.to(device)\n",
        "\n",
        "        xs_stacked = torch.tile(data_batch.view(-1, 28**2), (K, 1))\n",
        "        z_post_mu, z_post_log_sigma = enc(xs_stacked)\n",
        "        #z = sample_laplace(z_post_mu, z_post_log_sigma)\n",
        "        z = sample_gaussian(z_post_mu, z_post_log_sigma)\n",
        "\n",
        "        #z_prior_log_likelihood = laplace_log_likelihood(z, torch.zeros(z.shape).to(device), torch.zeros(z.shape).to(device))\n",
        "        z_prior_log_likelihood = normal_log_likelihood(z, torch.zeros(z.shape).to(device), torch.zeros(z.shape).to(device))\n",
        "        #z_post_log_likelihood = laplace_log_likelihood(z, z_post_mu, z_post_log_sigma)\n",
        "        z_post_log_likelihood = normal_log_likelihood(z, z_post_mu, z_post_log_sigma)\n",
        "        kl_z_prior_post = z_post_log_likelihood - z_prior_log_likelihood\n",
        "\n",
        "        xs_stacked_mu = gen(z, task, sampling_mode)\n",
        "        x_post_log_likelihood = bernoulli_log_likelihood(xs_stacked, xs_stacked_mu)\n",
        "\n",
        "        bound = (x_post_log_likelihood - kl_z_prior_post).reshape(K, data_batch.shape[0])\n",
        "        bound_max = torch.max(bound, dim=0).values\n",
        "        bound -= bound_max\n",
        "\n",
        "        log_norm_bound = torch.log(torch.clamp(torch.mean(torch.exp(bound), 0), 1e-9, np.inf))\n",
        "        test_ll = log_norm_bound + bound_max\n",
        "        test_ll_mean += torch.mean(test_ll) / total_batches\n",
        "        test_ll_std += torch.sqrt(torch.var(test_ll, correction=0) / test_ll.shape[0]) / total_batches\n",
        "\n",
        "    return test_ll_mean, test_ll_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yElB9gfHuHF2"
      },
      "outputs": [],
      "source": [
        "def train(task_traindata_dict, task_testdata_dict, enc, gen, hyperparams, device):\n",
        "    adam = Adam(list(enc.parameters()) + list(gen.parameters()), lr=hyperparams['lr'])\n",
        "    accuracies = []\n",
        "\n",
        "    for task, data in enumerate(task_traindata_dict.values()):\n",
        "        enc.train(); gen.train()\n",
        "        tmp_accuracies = []\n",
        "        print(\"Data for task\", task, \"arrives.\")\n",
        "\n",
        "        for epoch in range(hyperparams['n_epochs']):\n",
        "            kl1s = []; expecs = []; kl2s = []\n",
        "\n",
        "            total_data = len(data.sampler)\n",
        "\n",
        "            for data_batch, _ in data:\n",
        "                data_batch = data_batch.to(device)\n",
        "                adam.zero_grad()\n",
        "                loss, kl1, expec, kl2 = compute_loss(\n",
        "                    data_batch.view(-1, 28**2),\n",
        "                    enc, gen, task, total_data\n",
        "                )\n",
        "                kl1s.append(kl1); kl2s.append(kl2); expecs.append(expec)\n",
        "                loss.backward()\n",
        "                adam.step()\n",
        "\n",
        "            print('epoch:', epoch, 'with stats', sum(kl1s)/len(kl1s), sum(expecs)/len(expecs), sum(kl2s)/len(kl2s))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            enc.eval(); gen.eval()\n",
        "\n",
        "            for prev_task in range(task + 1):\n",
        "                #z = torch.log(torch.rand(hyperparams['dim_z'], dtype=tf.float32)) - \\\n",
        "                #    torch.log(torch.rand(hyperparams['dim_z'], dtype=tf.float32))\n",
        "                z = torch.randn(hyperparams['dim_z']).to(device)\n",
        "                x = generator(z, prev_task, sampling_mode=hyperparams['sampling_mode']).reshape(28, 28)\n",
        "                plt.imshow(x.cpu().detach().numpy(), cmap='gray', vmin=0.0, vmax=1.0)\n",
        "                plt.show()\n",
        "\n",
        "                test_ll_mean, test_ll_std = eval_test_ll_on_task(\n",
        "                    task_testdata_dict, prev_task, enc, gen,\n",
        "                    sampling_mode=hyperparams['sampling_mode']\n",
        "                )\n",
        "\n",
        "                print(\"On task:\", list(task_testdata_dict.keys())[prev_task],\n",
        "                      \"was achieved test_ll_mean:\", test_ll_mean,\n",
        "                      \"with test_ll_std:\", test_ll_std\n",
        "                )\n",
        "\n",
        "                tmp_accuracies.append((test_ll_mean, test_ll_std))\n",
        "\n",
        "        gen.update_shared_params_prior()\n",
        "        gen.reset_shared_params_log_sigmas()\n",
        "\n",
        "        accuracies.append(tmp_accuracies)\n",
        "\n",
        "    return accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MBi5RlTLuekU",
        "outputId": "73991b2f-4e2f-4e1f-fb7e-771fb050e7bb"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data for task 0 arrives.\n",
            "epoch: 0 with stats 5.889986863156326 -287.97892363732603 3535039.537815126\n",
            "epoch: 1 with stats 1.869368222080359 -198.9439075373802 3527852.218487395\n",
            "epoch: 2 with stats 7.1919384703916664 -171.23742316750918 3520589.4579831935\n",
            "epoch: 3 with stats 8.607184878918304 -154.83062526157923 3513320.649159664\n",
            "epoch: 4 with stats 9.388362291480313 -149.6359728644876 3506037.93907563\n",
            "epoch: 5 with stats 10.420098761550518 -144.29722313119584 3498743.1113445377\n",
            "epoch: 6 with stats 12.15617421895516 -135.56636419216125 3491442.7962184874\n",
            "epoch: 7 with stats 12.846843535158815 -129.30706665295511 3484139.4243697478\n",
            "epoch: 8 with stats 12.962857222356716 -125.66087963200417 3476831.661764706\n",
            "epoch: 9 with stats 12.987971297833099 -123.08937374082934 3469518.1764705884\n",
            "epoch: 10 with stats 13.37975930766899 -120.05228738223805 3462198.8928571427\n",
            "epoch: 11 with stats 13.97209155459364 -116.53398613168412 3454875.3466386553\n",
            "epoch: 12 with stats 14.289177317579254 -113.87614133177685 3447548.9894957985\n",
            "epoch: 13 with stats 14.482617177883116 -111.75534128141003 3440218.8235294116\n",
            "epoch: 14 with stats 14.634709887143945 -109.92230949081292 3432886.067226891\n",
            "epoch: 15 with stats 14.722962451582195 -108.20708439931148 3425550.6092436975\n",
            "epoch: 16 with stats 14.776635602742685 -106.6387315637925 3418212.367647059\n",
            "epoch: 17 with stats 14.877732677619997 -105.15881873379234 3410871.7983193276\n",
            "epoch: 18 with stats 14.94434217244637 -103.87571998403854 3403529.4663865548\n",
            "epoch: 19 with stats 15.058784829468287 -102.66244692762359 3396185.4348739497\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On task: 0 was achieved test_ll_mean: tensor(-111.8473, device='cuda:0') with test_ll_std: tensor(2.8322, device='cuda:0')\n",
            "Data for task 1 arrives.\n",
            "epoch: 0 with stats 6.655723202670062 -112.09475555419922 109048.73046875\n",
            "epoch: 1 with stats 7.369802188873291 -76.03523669772677 71155.17708333333\n",
            "epoch: 2 with stats 8.205290024368852 -64.13177374380606 64071.27855902778\n",
            "epoch: 3 with stats 8.013902731294985 -61.509653077302154 56084.802633101855\n",
            "epoch: 4 with stats 7.8343091222974985 -60.16544760244864 50438.254774305555\n",
            "epoch: 5 with stats 8.005583494680899 -58.74805374145508 46402.24178240741\n",
            "epoch: 6 with stats 8.418709956275093 -57.030426647045 43632.83703703704\n",
            "epoch: 7 with stats 8.613107402236373 -55.851952390317564 41108.01455439815\n",
            "epoch: 8 with stats 8.704946387255633 -54.991330238624855 38757.75280671296\n",
            "epoch: 9 with stats 8.841491678025987 -54.29200764408818 36583.44759837963\n",
            "epoch: 10 with stats 8.896009897302699 -53.64171713369864 34611.783796296295\n",
            "epoch: 11 with stats 8.962431618019387 -53.06059067337601 32859.88414351852\n",
            "epoch: 12 with stats 8.970096054783573 -52.54860944394712 31115.35486111111\n",
            "epoch: 13 with stats 8.985845269097222 -52.04117259272822 29606.27605613426\n",
            "epoch: 14 with stats 8.986705356174046 -51.63560273912218 28137.052155671296\n",
            "epoch: 15 with stats 8.991134911996348 -51.23559672037761 26811.867881944443\n",
            "epoch: 16 with stats 8.973087289598253 -50.79898435804579 25630.250390625\n",
            "epoch: 17 with stats 8.940305384883175 -50.36184344821506 24366.47456597222\n",
            "epoch: 18 with stats 8.973531157882125 -50.00420207270869 23327.054253472223\n",
            "epoch: 19 with stats 8.922669523733633 -49.50065313268591 22398.64626736111\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On task: 0 was achieved test_ll_mean: tensor(-171.5596, device='cuda:0') with test_ll_std: tensor(4.8178, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On task: 1 was achieved test_ll_mean: tensor(-53.2363, device='cuda:0') with test_ll_std: tensor(2.3560, device='cuda:0')\n",
            "Data for task 2 arrives.\n",
            "epoch: 0 with stats 6.255252401034038 -208.21294708251952 55290.721162923175\n",
            "epoch: 1 with stats 8.517290604114532 -177.03194402058918 34535.01484375\n",
            "epoch: 2 with stats 11.747521654764812 -162.90857988993326 32510.2806640625\n",
            "epoch: 3 with stats 13.053694160779317 -155.53424034118652 31851.540445963543\n",
            "epoch: 4 with stats 13.712074327468873 -151.01964467366537 30755.383219401043\n",
            "epoch: 5 with stats 14.313645402590433 -147.73598620096843 29437.718098958332\n",
            "epoch: 6 with stats 14.708372028668721 -145.2770960489909 28570.048209635417\n",
            "epoch: 7 with stats 15.2087699731191 -142.79540367126464 28085.15577799479\n",
            "epoch: 8 with stats 15.540756559371948 -140.79922752380372 27686.400732421876\n",
            "epoch: 9 with stats 15.788745244344076 -138.8977425893148 27693.556087239584\n",
            "epoch: 10 with stats 15.954608551661174 -137.4183640797933 27436.59884440104\n",
            "epoch: 11 with stats 16.13481868902842 -135.88387444814046 27566.633447265624\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-76ba98cce443>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_traindata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_testdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-903c5ce6347c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(task_traindata_dict, task_testdata_dict, enc, gen, hyperparams, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mdata_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0madam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 loss, kl1, expec, kl2 = compute_loss(\n\u001b[0m\u001b[1;32m     17\u001b[0m                     \u001b[0mdata_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-d0503580cd48>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(x_train, enc, gen, task, total_data, K)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_gaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_post_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_post_log_sigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx_mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mpost_x_log_likelihood\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbernoulli_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-2fa19a47e4e1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, task_ind, sampling_mode)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaskspec_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-2fa19a47e4e1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, sampling_mode)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-2fa19a47e4e1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, sampling_mode)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msampling_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_gaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_sigma_W\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_gaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_sigma_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-3a68ed6f6126>\u001b[0m in \u001b[0;36msample_gaussian\u001b[0;34m(mu, log_sigma)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# sample from N ~ N(mu, log_sigma)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample_gaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_sigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_sigma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbernoulli_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "accuracies = train(task_traindata_dict, task_testdata_dict, encoder, generator, hyperparams, device)\n",
        "print(accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkwVMN-xutDg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}